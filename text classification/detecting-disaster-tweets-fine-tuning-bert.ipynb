{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nimport pandas as pd\nimport numpy as np \nfrom scipy.special import softmax\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (roc_auc_score, classification_report, \n                             confusion_matrix)\nimport tensorflow as tf\nfrom transformers import BertTokenizer\nfrom transformers import TFBertForSequenceClassification\nfrom transformers import AutoConfig\n","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_data = pd.read_csv('../input/nlp-getting-started/train.csv')\nprint(train_data.shape)\ntrain_data.head(10)","execution_count":2,"outputs":[{"output_type":"stream","text":"(7613, 5)\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n5       1  \n6       1  \n7       1  \n8       1  \n9       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#flood #disaster Heavy rain causes flash flood...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I'm on top of the hill and I can see a fire in...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>There's an emergency evacuation happening now ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I'm afraid that the tornado is coming to our a...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The training dataset includes a column `text` with the text we must classify and an additional column `target` which tells us if the tweet is about a real disaster (1-> real disaster). The test dataset looks similar."},{"metadata":{"trusted":true},"cell_type":"code","source":"# load test dataset\ntest_data = pd.read_csv('../input/nlp-getting-started/test.csv')\nprint(test_data.shape)\ntest_data.head(10)","execution_count":3,"outputs":[{"output_type":"stream","text":"(3263, 4)\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n5  12     NaN      NaN                 We're shaking...It's an earthquake\n6  21     NaN      NaN  They'd probably still show more life than Arse...\n7  22     NaN      NaN                                  Hey! How are you?\n8  27     NaN      NaN                                   What a nice hat?\n9  29     NaN      NaN                                          Fuck off!","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>We're shaking...It's an earthquake</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>21</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>They'd probably still show more life than Arse...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Hey! How are you?</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>27</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What a nice hat?</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fuck off!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for tweet_index in range(1,30,5):\n    print(f'Text of the tweet: {train_data[\"text\"][tweet_index]}')\n    print(f'Target: {\"Real disaster\" if train_data[\"target\"][tweet_index]==1 else \"Not real disaster\"}\\n')","execution_count":4,"outputs":[{"output_type":"stream","text":"Text of the tweet: Forest fire near La Ronge Sask. Canada\nTarget: Real disaster\n\nText of the tweet: #flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas\nTarget: Real disaster\n\nText of the tweet: Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding\nTarget: Real disaster\n\nText of the tweet: I love fruits\nTarget: Not real disaster\n\nText of the tweet: London is cool ;)\nTarget: Not real disaster\n\nText of the tweet: Was in NYC last week!\nTarget: Not real disaster\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data[\"target\"])","execution_count":5,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n","name":"stderr"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"<AxesSubplot:xlabel='target', ylabel='count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd94bad483e5468e87af9a011ad17abb"}},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_sequence(text):\n    \n\n    prepared_sequence = tokenizer.encode_plus(\n                            text, \n                            add_special_tokens = True, \n                            max_length = 512, \n                            padding = 'max_length',\n                            return_attention_mask = True\n                            )\n    return prepared_sequence","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare a test sentence\ntest_sentence = 'Is this jacksonville?'\ntest_sentence_encoded = prepare_sequence(test_sentence)\ntoken_ids = test_sentence_encoded[\"input_ids\"]\n","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preparation"},{"metadata":{},"cell_type":"markdown","source":"We build the training and validation datasets in the format expected by the `TFBertForSequenceClassification` model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n   \n    mapped_example = {\n        \"input_ids\": input_ids,\n        \"token_type_ids\": token_type_ids,\n        \"attention_mask\": attention_masks,\n    }\n    return mapped_example, label \n\ndef encode_examples(texts_and_labels):\n    \"\"\"\n    Prepare all sequences of text and build TF dataset.\n    \"\"\"\n\n    input_ids_list = []\n    token_type_ids_list = []\n    attention_mask_list = []\n    label_list = []\n        \n    for text, label in texts_and_labels:\n\n        bert_input = prepare_sequence(text)\n\n        input_ids_list.append(bert_input['input_ids'])\n        token_type_ids_list.append(bert_input['token_type_ids'])\n        attention_mask_list.append(bert_input['attention_mask'])\n        label_list.append([label])\n\n    # Create TF dataset\n    dataset = tf.data.Dataset.from_tensor_slices(\n        (input_ids_list, attention_mask_list, token_type_ids_list,\n         label_list)\n    )\n    # Map to the expected input to TFBertForSequenceClassification\n    dataset_mapped = dataset.map(map_example_to_dict)\n    return dataset_mapped","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data[\"text\"]\ny = train_data[\"target\"]\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, \n                                                    random_state=1)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_training_examples = X_train.shape[0]\nn_positive_training_examples = y_train.value_counts()[1]\nn_negative_training_examples = y_train.value_counts()[0]\nprint(f'Number examples in training dataset: {n_training_examples}')\nprint(f'Number of positive examples in training dataset: {n_positive_training_examples}')\nprint(f'Number of negative examples in training dataset: {n_negative_training_examples}')","execution_count":16,"outputs":[{"output_type":"stream","text":"Number examples in training dataset: 6851\nNumber of positive examples in training dataset: 2947\nNumber of negative examples in training dataset: 3904\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = list(zip(X_train, y_train))\nval_dataset = list(zip(X_val, y_val))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare sequences of text and build TF train dataset\nds_train_encoded = encode_examples(train_dataset).shuffle(10000).batch(20)\n\n# Prepare sequences of text and build TF validation dataset\nds_val_encoded = encode_examples(val_dataset).batch(20)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    # Define the configuration of the model\n    config = AutoConfig.from_pretrained('bert-base-uncased',\n                                        hidden_dropout_prob=0.2,\n                                        num_labels=2)\n    # Model initialization\n    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', \n                                                            config=config)\n    return model","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model initialization\nmodel = get_model()\n\n# Define the optimizer, the loss function and metrics\noptimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n# Compile the model\nmodel.compile(optimizer=optimizer, loss=loss, metrics=[metric])","execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b9c371a9be247c596d2114fb6db3033"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/536M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b695d099c39944e5ab70a09ed354108c"}},"metadata":{}},{"output_type":"stream","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['mlm___cls', 'nsp___cls']\n- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['dropout_37', 'classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"## Model training"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nweight_for_0 = (1 / n_negative_training_examples)*(n_training_examples)/2.0 \nweight_for_1 = (1 / n_positive_training_examples)*(n_training_examples)/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","execution_count":21,"outputs":[{"output_type":"stream","text":"Weight for class 0: 0.88\nWeight for class 1: 1.16\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\nmodel.fit(ds_train_encoded, epochs=10, validation_data=ds_val_encoded,\n          class_weight = class_weight)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nval_predictions = model.predict(ds_val_encoded)\nval_probabilities = softmax(val_predictions[0], axis=1)\ny_val_predictions = np.argmax(val_probabilities, axis=1).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclassification_metrics = classification_report(y_val, y_val_predictions)\n\narea_under_the_curve = roc_auc_score(y_val, val_probabilities[:,1:2], multi_class=\"ovr\")\n\nerror_matrix = confusion_matrix(y_val, y_val_predictions)\nprint(f'Area under the ROC curve: {area_under_the_curve}')\nprint(f'Classification metrics:\\n{classification_metrics}')\n\nax = plt.axes()\nsns.heatmap(error_matrix, annot=True, fmt=\"d\")\nax.set_title('Confusion matrix Validation set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_test_examples(texts):\n    \"\"\"\n    Prepare all sequences of text and build TF dataset.\n    \"\"\"\n\n    input_ids_list = []\n    token_type_ids_list = []\n    attention_mask_list = []\n        \n    for text in texts:\n\n        bert_input = prepare_sequence(text)\n\n        input_ids_list.append(bert_input['input_ids'])\n        token_type_ids_list.append(bert_input['token_type_ids'])\n        attention_mask_list.append(bert_input['attention_mask'])\n\n    # Create TF dataset\n    dataset = tf.data.Dataset.from_tensor_slices(\n        (input_ids_list, attention_mask_list, token_type_ids_list)\n    )\n    # Map to the expected input to TFBertForSequenceClassification\n    dataset_mapped = dataset.map(map_test_example_to_dict)\n    return dataset_mapped\n\ndef map_test_example_to_dict(input_ids, attention_masks, token_type_ids):\n    \n    mapped_example = {\n        \"input_ids\": input_ids,\n        \"token_type_ids\": token_type_ids,\n        \"attention_mask\": attention_masks,\n    }\n    return mapped_example","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_data[\"text\"]\ntest_dataset = list(X_test)\nds_test_encoded = encode_test_examples(test_dataset).batch(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = model.predict(ds_test_encoded)\ntest_probabilities = softmax(test_predictions[0], axis=1)\ny_test_predictions = np.argmax(test_probabilities, axis=1).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy the results to a pandas dataframe with an \"id\" column and a \"target\" column\nfinal_submission = pd.DataFrame( data={\"id\":test_data[\"id\"], \"target\":y_test_predictions})\n# Save the submission file\nfinal_submission.to_csv(\"submissionTweets.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}